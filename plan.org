* Objectives - Grep for github 
 - Scan github for example that create data structures from scratch (list, hash map, circular list, tree, array) 
   + keywords e.g list, insert, append ?
 - Use GitHub search to find possible examples using keywords, file endings, language restriction 
 - Pull repositories for examples 
 - Utilise regular expressions to find exact examples of data structure of interest being defined (linked list)
 
* Thoughts
 - 1000 results return for each unique query (may return diff results if diff sorting parameter used, indexed or best match )
 - What form do they take ?
   + pull entire project ?
   + run generic makefile to check for the present of thing to transform
	 - what is it that is being transformed or looked for presence of
	 - linked list implementation
 - Pulling each repo to run regex over is going to be slow 
 - limitations of github to 30 requests per minute
 - Find file contents via various criteria. This method returns up to 100 results per page.
 - sort Default: best match
 - Simplest approach take the live-grep and feed the web server the repositories returned by the github code search (only uses keywords tho not true grep)
   + build 
 - having a local copy of github is insane so need to be smart use what github offers to reduce downloading repo locally for livegrep to search
 - GitHub Scaper to find interesting repo to clone and then regex (as GitHub Api will only return 1000 res)
 - Incrementaly go through number of stars definitly get diff list of 1000 repos each time :)
 - index files for repos are 5-6x larger than the repos :(
 - does livegrep have someway of paging results endlessly ? (max_matches exists but is that the best way)
 - Clang filtering of reposistories ? reduce the number of required repos to search across
 - Could build DB of every repo on github just having some information on it link to reposistory language information (seems possible)
 - Could build index of code on the fly from filtered list of repositories that are passed to code search tool (Repositories actual code could be stored locally if needed)
 - What are some local tools that are like grep for large set of files ? ([[https://github.com/google/codesearch][google code search tool]], [[https://beyondgrep.com/][ack - grep opt for programmers]], git grep, )
 - way to limit number of results from each repository

* Things I need to know ? 
 - What is going to use the result of the tool ? 
   + Rejuvenation tools
   + People interested in examples of code
 - Is this just for transformation examples related to my project ?
 - How limited is the results return by github, can I even get all matches github made.
 - How to get more results return than just 1000
 - How slow can it be ?
 - How interactive does it need to be?
 - what is pulled by livegrep github index tool (whole repo), can you provide non github repos ? (must be able to)
 - can livesearch index not stored in git repo
 - livegrep json list of repos pulled stored in same location as repos
 - what is the security concern of donwloading random repos off the internet
 - do repos have unique ids ?

* Links 
 - [[https://developer.github.com/v3/search/][GitHub Search api]]
   + The GitHub Search API provides up to 1,000 results for each search.
 - [[https://developer.github.com/v3/search/][GitHub Search api]]
   + to search code:  You must authenticate to search for code across all public repositories.
 - [[https://realpython.com/api-integration-in-python/][Restful APIs in python]]
 - [[https://github.com/PyGithub/PyGithub/issues/824][1000 request issue]]
 - [[https://www.alexdebrie.com/posts/faster-code-search-livegrep/][livegrep]] (pretty awesome)n
 - [[https://github.com/mamal72/telegram-github-search-bot][telegram github bot]]
 - [[https://github.com/mbcrawfo/GenericMakefile][Generic makefile]]
 - [[https://spin.atomicobject.com/2016/08/26/makefile-c-projects/][makefile c project]]
 - [[https://github.com/google/codesearch][google code search - set of commandline tools written in go]]
 - [[https://oracle.github.io/opengrok/][openGrok - source code search and cross reference engine]]
   + does it support regex => ([[https://github.com/oracle/opengrok/wiki/Comparison-with-Similar-Tools][only wildcards]])
 - [[https://searchcode.com/][Search code]] - searchcode server you can search across any repository of code that has been added by your administrator. 
   + does it support regex - (No regex)
	 - Search using wild-card operators E.G. search*,
	 - Search using boolean and search operators AND OR NOT ( ),
	 - Search using special characters E.G. i++;)
   + [[https://searchcode.com/?q=hello][searchcode website]] can search through repos from Github, Bitbucket, Google Code, CodePlex, GitLab, Sourceforge, Minix, Google , Gitorious 
	 so there must be away to get code info or repository info from each of these sites
 - Source graph (N/A)
 - [[http://www.lihaoyi.com/post/ReimaginingtheOnlineCodeExplorer.html][Reimagining the Online Code Explorer]] blog post (2017)
 - [[https://searchfox.org/][Search fox]], Create by mozila uses livegrep indexer, desc: Searchfox is a source code indexing tool for Mozilla Firefox
   + last update 2 years ago
   + gitrepo https://github.com/bgrins/searchfox has a nice diagram
 - [[https://github.com/hound-search/hound][Hound ]]: very simialr to livegrep build using Russ Cox: Regular Expression Matching with a Trigram Index.
   + "Create a config.json in a directory with your list of repositories."
   + supported version control systems Git, Mercurial, SVN, Bazaar can be specified per repo in json file

* Notes from trying stuff
 - using list as name of file leads to lot of cs student related learning reposistories
 - Backend and frontend deployed on server and but frontend can't communicate with backfront
   + direct calls to backend work using bloomRPC
   + does it work locally with bloomrpc ? (yes) once port is published
 - GITHUB API
   - If results returned by GitHub API are on multiple pages use ?page=3 to specify a page and ?per_page=100 to specify # max number on each page
   - For API requests using Basic Authentication or OAuth, you can make up to *5000* requests per hour.
   - For unauthenticated requests, the rate limit allows for up to *60* requests per hour. 
 - livegrep has specific file searching in a repo (could be used in conjunction with github api)
   + livegrep returns in code results and name file results
   + api for livegrep accessible https://livegrep.com/api/v1/search/ returns json, web query is https://livegrep.com/search/
   + custom indexing backend, uses Russ Cox's RE2 regex library
   + livegrep can timeout on large number of matches specified "why=TIMEOUT" but time spend is only 12s so could be extended sometime
	 + could be due to livegrep trying to be "live" to instantly return results
   + Walking HEAD like so  Walking repo_spec name=drx/kiwi, path=repos/drx/kiwi (including  submodules: false) is when index is being built for backend
   + commands like: codesearch_start -grpc localhost:9999  repos/livegrep.json with the repositories already download
	 - builds an in memory index for the backend for repo_pull_test5 which had 1 20.2G index file this is to large to be run
	 - this require an external memory mapped index file 

* Tasks
 1) Check the extent of github search functionality (write python code to get results and pull porjects)
	- how many keywords allowed to narrow search	

 2) How would pipeline work 1:
	- Users provide some restriction parameters that github can utilise to find repos/files
	- then User provides patterns of what they want to find (like grep) and they are applied to the repositories found earlier.
	  - how are regexs defined to identify linked list candidates?
	  - limited return of github maybe an issue
	  - time taken to download repository would be a problem ? 

 3) How would pipeline work 2:
	- regex provided	
	- then search made to GitHub api where regex is more specific
	- collect results from all searchs to the api and return them to the user

 4) Confirm Number of repositories GitHub Api can return (1000)
	- get more by using star count diff search 

 5) install livegrep on own machine using docker (stress test) (problematic failed to connect frontend to backend)
	- how to get livegrep to index a specific repo not a user
	  + docker run -v $(pwd):/data livegrep/indexer /livegrep/bin/livegrep-github-reindex -repo livegrep/livegrep -http -dir /data
	- test the backend codesearch running in docker with direct GRPD requests ([[https://github.com/uw-labs/bloomrpc][Bloomrpc]]) to ensure it works
	
 6) install livegrep on server using docker or build natively
	- install using blog post (done) or try livegrep repo docker install (trying local install to see if backend and talk to frontend and its just a docker error)
	- installed nativately and worked, built using bazel 0.26 slightly different from the one stated in projects github
	- Check different ways of build index of code or to run without building an index using native tool 
	- find way of passing repository from a list (or github api) to create an index for codesearch backend
	  + get top 1000 repo results for c language then  build index with the set of repos
	  + build a *JSON* file that specifies the required repos (THIS) (what are the formats for local repos, external repo on github (is this possible))
	  + use inbuilt github indexer and feed it a list a repos individually with flag -repo
	  + which is faster the github helper tool are starting codesearch directly with a index.json file ? (advantages/disadvantages)
	  + can livesearch index code not stored in git repo ?

 7) How large is GitHub (tb or pb) 
	- [[https://github.com/search?q=is:public][29 Million public repos]], max size [[https://help.github.com/en/articles/what-is-my-disk-quota][100GB]] so size <2800tb, (need better estimate obviously)
	- 400,000 GitHub repositories, 1 billion files, 14 terabytes of code - [[https://medium.com/@hoffa/400-000-github-repositories-1-billion-files-14-terabytes-of-code-spaces-or-tabs-7cfe0b5dd7fd][Medium]] 
	- so maybe 1015tb if (29M/400,000)*14tb (still not good)
	- repos that are designated c or c++ number around 1M, c = 470k and c++ = 649K
	  + so 2.5*14tb= 35tb for c/c++ repos

 8) What API/tool exist for GitLab/sourceForge/bitbucket or other source code hosting sites (codeplex, google code)
	- GitLab: has search capabilities and a Restful API
	  + [[https://docs.gitlab.com/ee/user/search/advanced_global_search.html][Advanced Global Search]] (powered by Elasticsearch) is not yet available on GitLab.com
	  + over 1000 repos returned for simple search of ruby pages can keep being request by the looks of it (unlike github)
	- [[https://confluence.atlassian.com/bitbucket/use-the-bitbucket-cloud-rest-apis-222724129.html][BitBucket]]: Restful api & code search ?
	  + Wildcard searches (e.g. qu?ck buil*) are not supported.
	  + Regular expressions in queries are not supported, but you can search for special characters.
	- SourceForge: multiple APIs 	  
	  + Allura API - A read/write API for reading/writing to project info, tickets, wiki pages, etc
	  + Download Stats API - A read-only API for obtaining download statistics
	  + File Release API - set the default download for your project.

 9) How well does GitHub Identify repo language types

 10) Test regex for iterator and see results on large collection
	 - Is the tool actually useful

 11) stress test 1000 repos



* Additional
  - check real-world implementations of linked lists how different people define them.
